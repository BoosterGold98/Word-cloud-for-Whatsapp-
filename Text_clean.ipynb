{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_clean.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvu6fSEjYercMS3h4ddEZI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BoosterGold98/Word-cloud-for-Whatsapp-/blob/master/Text_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZUXD4iJ5GxR",
        "colab_type": "text"
      },
      "source": [
        "# **Creating a word cloud for whatsapp chats**\n",
        "\n",
        "A word cloud is a data visual representation of text data, typically used to depict keywords in a free form text. This data visualization technique is useful for quickly perceiving the most prominent terms in a document. An example is shown below:\n",
        "\n",
        "![word cloud](https://altoona.psu.edu/sites/altoona/files/styles/photo_gallery_large/public/success-word-cloud.jpg?itok=ywo0g6Pf)\n",
        "\n",
        "A word cloud is a collection of words which vary in font size and colour according to significance or frequency of occurence. \n",
        "\n",
        "An alternative is creating a table for the occurences of words and while the table gives more accurate information, a word cloud makes that data more visually appealing and accentuates the most occuring words in a document.\n",
        "\n",
        "There is already a library in python called **wordcloud** which achieves the purpose of converting text into a wordcloud. Using the library, one can create wordclouds of various texts such as books or scripts. Here, implementation of wordcloud for a whatsapp text is achieved. The code is divided into two parts:\n",
        "\n",
        "1.   Pre processing of the text\n",
        "2.   Word cloud creation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpdVhH1b4_1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9cALdIP921t",
        "colab_type": "text"
      },
      "source": [
        "Importing all the dependenies for the code. The re library will be used for text clean up while the nltk library is used to import stopwords which will be used later.\n",
        "\n",
        "First lets take a look at the whatsapp chat when imported via the app.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "01/01/2030, 12:00 AM - Sender:   sample\n",
        "01/01/2030, 12:00 AM - Receiver: sample\n",
        "01/01/2030, 12:00 AM - Sender:   sample\n",
        "01/01/2030, 12:00 AM - Sender:   sample\n",
        "01/01/2030, 12:00 AM - Sender:   sample\n",
        "01/01/2030, 12:00 AM - Receiver: <Media ommitted>\n",
        "01/01/2030, 12:00 AM - Sender:   This message was deleted\n",
        "01/01/2030, 12:00 AM - Receiver: sample\n",
        "\n",
        "```\n",
        "The above is a sample whatsapp chat. We see that the sample is the actual message while the date and time stamp as well as the sender and receiver names are metadata. The word cloud requires only the text and nothing else. Listing the features needed to be discarded:\n",
        "\n",
        "\n",
        "\n",
        "1.   Emojis\n",
        "2.   Date and time stamps\n",
        "3.   Meta messages such as 'media omitted' and 'This message has been deleted'\n",
        "4.   Punctuations\n",
        "5.   Stray blank lines\n",
        "6.   Any character other than upper and lower case alphabets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlsTydhF-loI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJJDKtAsBuMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_string(string):\n",
        "    string = re.sub('<.*?>', '', string)                                # punctuations\n",
        "    expr = re.compile('\\d{2}/\\d{2}/\\d{4},')                             # Date\n",
        "    string = re.sub(expr, '', string)\n",
        "    expr1 = re.compile('\\d{1,2}\\:\\d{2} - ')                             # Time\n",
        "    string = re.sub(expr1, '', string)\n",
        "    string = re.sub('<Media omitted>', '', string)\n",
        "    string = re.sub('This message was deleted', '', string)\n",
        "    string = re.sub(r'.*:', '', string)                                 # Removing sender and receiver names \n",
        "    string = re.sub(r'[^\\w\\s]','',string)                               # Removing expressions other than upper and lowercase alphabets \n",
        "    string = re.sub('\\n\\s*\\n','\\n', string)                             # Removing stray blank lines\n",
        "    return string.lower()                                               # Converting all to lowercase for consistency of words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS5e-eWmCbY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"data.txt\"                                   # Whatsapp chat export renamed to data\n",
        "\n",
        "with open(file_name, encoding=\"utf8\") as chat:           # Encoding is utf8 since chats conatin emojis and cannot be read otherwise \n",
        "    chat_text = chat.read()\n",
        "\n",
        "text = remove_emoji(chat_text)\n",
        "text1 = remove_string(text)\n",
        "#print(text1)                                            # Uncomment this to check output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifmk_uIMC0J8",
        "colab_type": "text"
      },
      "source": [
        "Lets look at stopwords. Stop words are words which are filtered out before or after processing of natural language data (text). If one where to find the most occured word in a text, it would always will be 'the' followed by words like 'if', 'that', 'from', etc.  This info is useless and thus such words are removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGEdgBnHDssa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "words = text1.split() \n",
        "open('filteredtext.txt', 'w').close() # A seperate text file to store the cleaned text. This command always clears up contents of the text file every time this code is run\n",
        "for w in words: \n",
        "    if not w in stop_words: \n",
        "        appendFile = open('filteredtext.txt','a') \n",
        "        appendFile.write(\" \"+w) \n",
        "        appendFile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}